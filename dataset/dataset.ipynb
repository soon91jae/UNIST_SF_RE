{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = open('TACRED/TACRED.pkl','rb')\n",
    "tacred = pickle.load(fin)\n",
    "\n",
    "tacred_train = tacred['train']\n",
    "tacred_test = tacred['test']\n",
    "tacred_dev = tacred['dev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ans_type', 'relation', 'tokens', 'ans_end', 'id', 'deprel', 'pos', 'key_end', 'ans_start', 'ner', 'head', 'key_type', 'sentence', 'key_start'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tacred_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_format(tokens, lower, zeros):\n",
    "    tokens = \" \".join(tokens)\n",
    "    if zeros:\n",
    "        tokens = re.sub('\\d', '0', tokens)\n",
    "    if lower:\n",
    "        tokens = token.lower()\n",
    "    return tokens.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, \n",
    "                    # options related to the word format\n",
    "                    lower = False,\n",
    "                    zeros = True,\n",
    "                    # options for the features\n",
    "                    #pos_feature = True,\n",
    "                    #positional_feature = True,\n",
    "                    # options for the (subj, obj) representation\n",
    "                    position_indicator = False,\n",
    "                    subj_obj_normalization = True,\n",
    "                    **kwargs):\n",
    "    assert position_indicator^subj_obj_normalization, '(positional_indicator, subj_obj_normalization) should be (True, False) or (False, True)'\n",
    "    \n",
    "    \n",
    "    for data in dataset:\n",
    "        sent_id = data['id']\n",
    "        sentence = data['sentence']\n",
    "        tokens = data['tokens']\n",
    "        pos = data['pos']\n",
    "        ner = data['ner']\n",
    "        heads = data['head']\n",
    "        deprel = data['deprel']\n",
    "        \n",
    "        key_start = data['key_start']\n",
    "        key_end = data['key_end']\n",
    "        key_type = data['key_type']\n",
    "        \n",
    "        ans_start = data['ans_start']\n",
    "        ans_end = data['ans_end']\n",
    "        ans_type = data['ans_type']\n",
    "        \n",
    "        relation = data['relation']\n",
    "        \n",
    "        if zeros or lower:\n",
    "            tokens = word_format(tokens, lower, zeros)\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if subj_obj_normalization:\n",
    "            for i, d in enumerate(zip(tokens, pos, ner, heads, deprel)):\n",
    "                _t, _p, _n, _h, _d = d\n",
    "                if i >= key_start and i <= key_end: \n",
    "                    tokens[i] = \"SUBJ_\" + key_type\n",
    "                elif i >= ans_start and i <= ans_end:\n",
    "                    tokens[i] = \"OBJ_\" + ans_type\n",
    "                \n",
    "        else: # subj obj normalize\n",
    "            new_tokens = []\n",
    "            new_pos = []\n",
    "            new_ner = []\n",
    "            new_heads = []\n",
    "            new_deprel = []\n",
    "\n",
    "            new_key_start = []\n",
    "            new_key_end = []\n",
    "            \n",
    "            \n",
    "    data['id'] = sent_id\n",
    "    data['sentence'] = sentence\n",
    "    data['tokens'] = tokens\n",
    "    data['pos'] = pos\n",
    "    data['ner'] = ner\n",
    "    data['head'] = heads\n",
    "    data['deprel'] = deprel\n",
    "        \n",
    "    data['key_start'] = key_start\n",
    "    data['key_end'] = key_end \n",
    "    data['key_type'] = key_type\n",
    "        \n",
    "    data['ans_start'] = ans_start\n",
    "    data['ans_end'] = ans_end\n",
    "    data['ans_type'] = ans_type\n",
    "        \n",
    "    data['relation'] = relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Her chief spokesman in the governor 's office , Bill McAllister , said her aggressive role in the presidential campaign reflected the job she was given , not a change of character .\n",
      "['SUBJ_PERSON', 'chief', 'spokesman', 'in', 'the', 'governor', \"'s\", 'office', ',', 'OBJ_PERSON', 'OBJ_PERSON', ',', 'said', 'her', 'aggressive', 'role', 'in', 'the', 'presidential', 'campaign', 'reflected', 'the', 'job', 'she', 'was', 'given', ',', 'not', 'a', 'change', 'of', 'character', '.']\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset(tacred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
